{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d833ca84",
   "metadata": {},
   "source": [
    "### Tutorial 4: Use stCAMBL model to train on the hippocampal dataset to obtain reconstructed features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32783bc8",
   "metadata": {},
   "source": [
    "In this tutorial, we will show how to use the model to train on the hippocampal dataset to obtain reconstructed features, this will prepare for the subsequent Celina analysis. Relevant data can be obtained from github."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad47ea",
   "metadata": {},
   "source": [
    "**Import the relevant python analysis package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e068ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import torch\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import stCAMBL\n",
    "import os\n",
    "import rpy2.robjects as ro\n",
    "#Please change this path to your local R environment path\n",
    "os.environ['R_HOME'] = '/data3/wkcui/env/anaconda3/envs/stCAMBL/lib/R'\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ae67b",
   "metadata": {},
   "source": [
    "**Read data and perform data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "def99b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.r('load(\"/data3/yfchen/stCAMBL/data/hp/hippocampus_scRNA_reference.RData\")')\n",
    "# obtain scRNA-seq data and metadata\n",
    "counts = ro.r(\"\"\"\n",
    "    list(\n",
    "        matrix = as.matrix(scRNA_count_subset),\n",
    "        genes = rownames(scRNA_count_subset),\n",
    "        cells = colnames(scRNA_count_subset)\n",
    "    )\n",
    "\"\"\")\n",
    "meta = ro.r(\"\"\"\n",
    "    list(\n",
    "        cellType = sc_meta_in_subset$cellType,\n",
    "        sampleInfo = sc_meta_in_subset$sampleInfo,\n",
    "        cellID = sc_meta_in_subset$cellID\n",
    "    )\n",
    "\"\"\")\n",
    "ro.r('load(\"/data3/yfchen/stCAMBL/data/hp/starmap_plus_data_use.RData\")')\n",
    "\n",
    "# obtain spatial transcriptomics data\n",
    "data_use = ro.r('data_use')\n",
    "spot_ids = np.array(ro.r('rownames(data_use$celltype_proportion)'))\n",
    "\n",
    "# get location_use\n",
    "location_df = data_use.rx2('location_use')\n",
    "location_use = np.column_stack((\n",
    "    np.array(location_df.rx2('x')),\n",
    "    np.array(location_df.rx2('y'))\n",
    "))\n",
    "\n",
    "# obtain expression matrix for selected spots\n",
    "all_colnames = np.array(ro.r('colnames(data_use$raw_matrix)'))\n",
    "spot_indices = np.where(np.isin(all_colnames, spot_ids))[0]\n",
    "expr_use = np.array(data_use.rx2('raw_matrix'))[:, spot_indices]\n",
    "\n",
    "# obtain cell type proportions for selected spots\n",
    "celltype_rows = np.array(ro.r('rownames(data_use$celltype_proportion)'))\n",
    "mask = np.isin(celltype_rows, spot_ids)\n",
    "celltype_use = np.array(data_use.rx2('celltype_proportion'))[mask, :]\n",
    "\n",
    "# obtain spatial coordinates for selected spots\n",
    "location_rows = np.array(ro.r('rownames(data_use$location_use)'))\n",
    "mask = np.isin(location_rows, spot_ids)\n",
    "location_use = location_use[mask, :]\n",
    "\n",
    "# create AnnData object\n",
    "adata = ad.AnnData(\n",
    "    X=scipy.sparse.csr_matrix(expr_use.T), \n",
    "    var=pd.DataFrame(index=np.array(data_use.rx2('raw_matrix').rownames)),  \n",
    "    obs=pd.DataFrame(index=spot_ids)  \n",
    ")\n",
    "df_meta = pd.read_csv('/data3/yfchen/stCAMBL/data/hp/ground_truth_hp.csv', sep='\\t')\n",
    "adata.obs['ground_truth'] = df_meta['layer_guess'].values\n",
    "adata.obsm['spatial'] = location_use\n",
    "adata.obsm['celltype_proportion'] = celltype_use\n",
    "\n",
    "# Data preprocessing\n",
    "sc.pp.filter_genes(adata, min_cells=50)\n",
    "sc.pp.filter_genes(adata, min_counts=10)\n",
    "adata_X_ori = adata.X.copy()  # 保存原始数据\n",
    "sc.pp.normalize_total(adata, target_sum=1e6)\n",
    "sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\",n_top_genes=2000)\n",
    "adata_X_ori = adata_X_ori[:, adata.var['highly_variable'] == True]\n",
    "adata = adata[:, adata.var['highly_variable'] == True]\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "dataset = 'Hippocampus'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af085bc",
   "metadata": {},
   "source": [
    "**Perform stCAMBL analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d516e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:28<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=200, random_state=42)\n",
    "adata_X = pca.fit_transform(adata.X)\n",
    "\n",
    "adata.obsm['X_pca'] = adata_X\n",
    "graph_dict = stCAMBL.graph_construction(adata, 12)\n",
    "model = stCAMBL.stCAMBL(adata.obsm['X_pca'], graph_dict, device=device)\n",
    "# Begin to train the model\n",
    "model.train_model(epochs=300, dataset=dataset)\n",
    "mapgcl_feat, defeat, _, _, _ = model.process()\n",
    "adata.obsm['emb'] = mapgcl_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd1d2c",
   "metadata": {},
   "source": [
    "**Reconstruct features to the original dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a96e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize_total(adata_norm):\n",
    "    original_sums = adata_norm.var['n_counts'].values  \n",
    "    X_norm = adata_norm.X.toarray() if hasattr(adata_norm.X, \"toarray\") else adata_norm.X\n",
    "    X_original = X_norm * (original_sums / 1e6) \n",
    "    adata_original = adata_norm.copy()\n",
    "    adata_original.X = X_original\n",
    "    return adata_original\n",
    "\n",
    "def inverse_scale(adata_scaled):\n",
    "    mean = adata_scaled.var['mean'].values\n",
    "    std = adata_scaled.var['std'].values\n",
    "    X_scaled = adata_scaled.X.toarray() if hasattr(adata_scaled.X, \"toarray\") else adata_scaled.X\n",
    "    X_original = X_scaled * std + mean\n",
    "    adata_original = adata_scaled.copy()\n",
    "    adata_original.X = X_original\n",
    "    return adata_original\n",
    "\n",
    "adata_rec = pca.inverse_transform(defeat)  \n",
    "adata.X = adata_rec \n",
    "adata_inv = inverse_scale(adata) \n",
    "adata_inv = inverse_normalize_total(adata_inv) \n",
    "adata.obsm['X_rec'] = adata_inv.X\n",
    "# Please replace the save path\n",
    "np.savetxt(\n",
    "        f\"/data3/yfchen/stCAMBL/hippocampus.txt\",\n",
    "        adata.obsm['X_rec'], \n",
    "        fmt='%.6f', \n",
    "        delimiter=' ',\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MapEnv_conda_backup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
